Solution 1.(a)
Multiprogramming Multiprocessing
Multiprogramming is also the ability of an
operating system to execute more than
one program on a single processor
machine. More than one
task/program/job/process can reside into
the main memory at one point of time.
Multiprocessing is the ability of an
operating system to execute more than
one process simultaneously on a multi
processor machine. In this, a computer uses
more than one CPU at a time.
The main idea of multiprogramming is to
maximize the use of CPU time. Indeed,
suppose the currently running process is
performing an I/O task. Then, the OS may
interrupt that process and give the control
to one of the other in-main-memory
programs that are ready to execute.
Multiprocessing refers to the hardware
(i.e., the CPU units) rather than the
software (i.e., running processes). If the
underlying hardware provides more than
one processor then that is multiprocessing.
A computer running excel and firefox
browser simultaneously is an example of
multiprogramming.
Processing on a computer with multiple
cores is an example of multiprocessing.
Solution 1.(b)
Process Threads
A process is an executing instance of an
application. Each process provides the
resources needed to execute a program.
Each process is started with a single
thread, often called the primary thread,
but can create additional threads from any
of its threads.
A thread is a path of execution within a
process. All threads of a process share its
virtual address space and system
resources. Threads can also have their own
security context, kernal registers and
environment block.
Solution 2.
Responsibilities of the OS includes:
• Convenient, feature-rich and secure interface for applications and hardware.
• Hiding the complexities of hardware from the user.
• Managing the resources including processors, memory, data storage and I/O
devices that can be accessed by different applications.
• Handling “interrupts” generated by the I/O controllers.
Solution 3.
A total of 9 process states are recognized by the UNIX operating system.
1. User Running- Executing in use mode.
2. Kernel running- Executing in kernel mode.
3. Ready to run in memory- Ready to run as soon as the kernel schedules it.
4. Asleep in memory- Waiting for an event. unable to execute until an event occurs.
Process is in main memory.
5. Ready to run, Swapped- Process is ready to run. But the swapper must swap the
process into main memory before the kernel can schedule it to execute.
6. Sleeping, Swapped- the process is awaiting an event and has been swapped to
secondary storage.(a blocked state)
7. Preempted- Process is returning from kernel to user mode, but the kernel
preempt it so as to switch to another process with a higher priority.
8. Created- process is newly created and not yet ready to run.
9. Zombie- process no longer exist, but it leaves a record for its parents process to
collect.
The running state is divided into 2 states, to distinguish when the process is running in
the user mode and in the kernel mode. Note that when running in the kernel mode, the
process is in fact running OS code.The UNIX state diagram reflects the view that the OS
runs in the context of processes. The advantage of this approach is to reduce process
switching. When the kernel code has completed and no process switching is required
(e.g. the system call was satisfied immediately), then control is simply returned to the
user code. Thus the OS is seen as a collection of subprograms run in kernel mode when
some interrupt or system trap occurs.
The zombie state corresponds to the terminated state.
Asleep in memory corresponds to the waiting state.
When a process is created, it is placed in the hard drive when insufficient memory is
available to run a process.
The Preempted state and ready to run in memory state are essentially the same state (as
indicated by the dotted line). Processes in either state are placed in the same scheduling
queue (the ready queue). When the kernel is ready to return control to the user
program, it may decide to preempt the current process in favor of another that is ready
and has a higher priority. In this case, the current process is placed in the preempted
state.
Solution 4.
For Windows thread diagram:
Ready: A ready thread may be scheduled for execution. The Kernel dispatcher keeps
track of all ready threads and schedules them in priority order.
Standby: A standby thread has been selected to run next on a particular processor. The
thread waits in this state until that processor is made available.If the standby thread’s
priority is high enough, the running thread on thatprocessor may be preempted in favor
of the standby thread. Otherwise, thestandby thread waits until the running thread
blocks or exhausts its time slice.
Running: Once the Kernel dispatcher performs a thread switch, the standbythread
enters the Running state and begins execution and continues execution until it is
preempted by a higher-priority thread, exhausts its time slice, blocks, or terminates. In
the first two cases, it goes back to the Ready state.
Waiting: A thread enters the Waiting state when it is blocked on an event (e.g., I/O), or
it voluntarily waits for synchronization purposes. When the waiting condition is satisfied,
the thread moves to the Ready state if all of its resources are available.
Transition: A thread enters this state after waiting if it is ready to run but the resources
are not available. For example, the thread’s stack may be paged out of memory. When
the resources are available, the thread goes to the Ready state.
Terminated: A thread can be terminated by itself, by another thread, or when its parent
process terminates. Once housekeeping chores are completed, the thread is removed
from the system, or it may be retained by the Executive 6 for future reinitialization.
For UNIX thread diagram:
Running: This state value corresponds to two states. A Running process is either
executing or it is ready to execute.
Interruptible: This is a blocked state, in which the process is waiting for an event, such
as the end of an I/O operation, the availability of a resource, or a signal from another
process.
Uninterruptible: This is another blocked state. The difference between this and the
Interruptible state is that in an Uninterruptible state, a process is waiting directly on
hardware conditions and therefore will not handle any signals.
Stopped: The process has been halted and can only resume by positive action from
another process. For example, a process that is being debugged can be put into the
Stopped state.
Zombie: The process has been terminated but, for some reason, still must have its task
structure in the process table.
Solution 5.
1) In Linux, the Process address space is split into two parts, the userspace part
which potentially changes with each full context switch and the kernel address
space which remains constant. In Linux kernel, normally 896MB physical memory
is mapped into kernal address space, with the rest being used for kernel data
structures, memory maps, page tables and such. In windows, there is no static
mapping of the physical memory to the kernal addressing space.
2) A translation lookaside buffer (TLB) is a memory cache that stores recent
translations of virtual memory to physical addresses for faster retrieval. When a
virtual memory address is referenced by a program, the search starts in the TLB.
Since every access to memory must be mapped from virtual to physical address,
reading the page table every time can be quite costly. Therefore, TLB is often
used. In windows kernel and applications can use x86 large pages for TLB
efficiency.
3) Paging is a method of writing data to, and reading it from, secondary storage for
use in primary storage, also known as main memory. Paging plays a role in
memory management for a computer's OS. In Linux, the memory owned by the 
kernel is physical RAM and is not capable of paging to disk. There is no
fundamental reason that kernel memory must not be page-able, but many
kernels, including Linux, don't page kernel memory as the complexity outweighs
the benefit. While in windows much of the code and data for kernel and drivers
are pageable.
4) Address Windowing Extensions (AWE) is a set of extensions that allows software
application to access andmanipulate physical memory greater than 4GB. Certain
data-intensive applications, such as database management systems and scientific
and engineering software, need access to very large caches of data. In the case of
very large data sets, restricting the cache to fit within an application's 2GB of user
address space is a severe restriction.
5) In Linux, user memory and kernel memory are independent and implemented in
separate address spaces. The kernel resides in one address space, and each
process resides in its own address space. These address spaces consist of virtual
memory addresses, permitting many processes with independent address spaces.
It's also secure, because each address space is independent and isolated. But linux
can also be used "4G/4G split" mode. In this mode, userspace has full access to the
entire 4GB virtual address space, and the kernel also has a full 4GB virtual address
space. This is not possible in windows, where it is common to reserve the top 1GB
or 2GB of virtual address space for kernel use.
6) A virtual memory management system maps the virtual addresses of the pages
with the physical addresses of the pages after the pages of the program has been
loaded at RAM in windows. While Linux uses a translation lookaside buffer (TLB)
for paging system.
7) In windows, virtual and physical memory are divided into handy sized chunks
called pages. In this paged model, a virtual address is composed of two parts; an
offset and a virtual page frame number. The Page Frame Number database
contains lists that represent the physical memory pages of the system. The kernel
translates the virtual page frame number to a physical one using the database and
then access the location of physical page. The kernel also uses the lists to track
which pages are “in use” (allocated to working sets), free, available, and so on.
While in linux, a page cache stores the pages that are removed from process
address space.
8) Windows uses a working set page replacement algorithm. The set of pages that a
process is currently using is called its working set. The paging system try to keep
track of each process' working set and make sure that it is in memory before
letting the process run.This strategy is called demand paging because pages are
loaded only on demand, not in advance. While linx uses, global clock algorithm. A
global replacement algorithm is free to select any page in memory.